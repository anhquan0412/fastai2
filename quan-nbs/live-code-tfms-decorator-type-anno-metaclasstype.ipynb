{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/quantran/.fastai/data/mnist_tiny/train/7/9286.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = untar_data(URLs.MNIST_TINY)/'train'\n",
    "items = get_image_files(source)\n",
    "fn = items[0]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-74b13307e3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e69650f4afb8>\u001b[0m in \u001b[0;36mneg\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'tuple'"
     ]
    }
   ],
   "source": [
    "neg((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(array((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform decorator can make a function work in a flexible way (inputs with different type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def neg(x): return -x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This @Transform looks like you gonna pass the func (neg) in ```__init__``` of class Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent\n",
    "def _neg(x): return -x\n",
    "neg = Transform(_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, -2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg((1,2)) # this is like calling encode function in Transform class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmElEQVR4nGNgGDaAEcbwUrvpLsxocmP5SiyqCv79+3X8xPFH7wWwSJb/c1ZkYGAw+ueBEGOCMXQYHt5nYGD4jKyBiQEPgEsyfvzGwMDAYP1uBxZVPPoMDAwMDJtf4zaI4/493Hbqy28i2UEwdzHikfx/Bp+xN3FLquOz0xifJIp70CVX/8cj+YtBD7ckA4MOHsnPa9FV4wIAY6Uh9HUz4SgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F7EC67F6F90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_image(fn)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tensor(array(img))\n",
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,  92,  17, 230,   0,   0,   0,\n",
       "           0, 160,  20,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0, 244, 209,   0,   0,   0,   0,\n",
       "           0,  77,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg(t[12:14]) # negative here doesn't really work, due to type uint8 doesn't allow negative number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0., -164., -239.,\n",
       "          -26.,   -0.,   -0.,   -0.,   -0.,  -96., -236.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.],\n",
       "        [  -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,  -12.,  -47.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0., -179., -235.,   -0.,   -0.,   -0.,\n",
       "           -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.,   -0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_float = t.float()\n",
    "neg(t_float[12:14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that @Transform will reserve type (see below, search for 'reserve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick note on the use of partial function and decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial: to set up certain keyword arguments before hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_func(a,b): return a+b\n",
    "\n",
    "sum_func(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_func2 = partial(sum_func,1) #add kwargs {a:1} to sum_func\n",
    "sum_func2(2) # only need to provide argument b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorator: wrappers to existing functions, to reuse/ add new functionality to existing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_func(a,b): return a+b # the existing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deco(f):\n",
    "    def _func(a,b): return f(a,b) # does nothing\n",
    "    return _func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func = deco(sum_func)\n",
    "my_func(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deco(f):\n",
    "    def _func(a,b): return 1+ f(a,b) # does new thing to existing f, e.g. increase value by 1\n",
    "    return _func\n",
    "\n",
    "my_func = deco(sum_func)\n",
    "my_func(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or use decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@deco\n",
    "def sum_func(a,b): return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func = sum_func # deco function (with sum_func as parameter) is called, and _func is returned (without any input params)\n",
    "my_func(1,2) # put params a and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine decorator and partial\n",
    "\n",
    "To reuse/add new stuff to existing functions and set up certain kwargs before hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deco(f):\n",
    "    def _func(a,b): return partial(f,a,b) # note that this function returns a partial function, \n",
    "    # not a value from a function like above\n",
    "    return _func\n",
    "\n",
    "@deco\n",
    "def sum_func(a,b,c): return a+b+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func = sum_func(1,2) # deco is called, _func is returned. _func is provided 2 input for parameters a and b\n",
    "my_func(3) # provide argument c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_func2 = sum_func(3,3) # my_func2 is a NEW variety of the old function sum_func (because of new kwargs)\n",
    "my_func2(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch: add new function (or property aka variables) to existing class using decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_func(f):\n",
    "    \"Copy a non-builtin function (NB `copy.copy` does not work for this)\"\n",
    "    if not isinstance(f,FunctionType): return copy(f)\n",
    "    fn = FunctionType(f.__code__, f.__globals__, f.__name__, f.__defaults__, f.__closure__)\n",
    "    fn.__dict__.update(f.__dict__)\n",
    "    return fn\n",
    "\n",
    "def patch_to(cls, as_prop=False):\n",
    "    \"Decorator: add `f` to `cls`\"\n",
    "    if not isinstance(cls, (tuple,list)): cls=(cls,)\n",
    "    def _inner(f):\n",
    "        # to check when adding new func to class, all the metadata are still correct\n",
    "        for c_ in cls:\n",
    "            nf = copy_func(f)\n",
    "            # `functools.update_wrapper` when passing patched function to `Pipeline`, so we do it manually\n",
    "            for o in functools.WRAPPER_ASSIGNMENTS: setattr(nf, o, getattr(f,o))\n",
    "            nf.__qualname__ = f\"{c_.__name__}.{f.__name__}\"\n",
    "            \n",
    "            # in class c, set function 'nf' (because copy_func) with f.__name__ as the class property\n",
    "            setattr(c_, f.__name__, property(nf) if as_prop else nf)\n",
    "        return f\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExistingClass(int): pass\n",
    "\n",
    "@patch_to(ExistingClass)\n",
    "def func1(x, a): return x+a\n",
    "\n",
    "# add func1 to class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ExistingClass(1)\n",
    "assert t.func1(2)==3\n",
    "assert t.func1(1)==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExistingClassTemp(int):\n",
    "    def func1(self, a): return self+a\n",
    "    \n",
    "t = ExistingClassTemp(1)\n",
    "assert t.func1(2)==3\n",
    "assert t.func1(1)==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add function f to multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExistingClass2(int): pass\n",
    "@patch_to((ExistingClass,ExistingClass2))\n",
    "def func2(x, a): return x+2*a\n",
    "\n",
    "t = ExistingClass(1)\n",
    "test_eq(t.func2(1), 3)\n",
    "t = ExistingClass2(1)\n",
    "test_eq(t.func2(1), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want to get the class automatically from function param instead of doing @patch_to(class_name) everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch(f):\n",
    "    \"Decorator: add `f` to the first parameter's class (based on f's type annotations)\"\n",
    "    cls = next(iter(f.__annotations__.values())) # find type (class) of f's parameter\n",
    "    return patch_to(cls)(f) # add function f to class cls found above\n",
    "\n",
    "@patch\n",
    "def func(x:ExistingClass, a):\n",
    "    \"test\"\n",
    "    return x+2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([<class '__main__.ExistingClass'>])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "__main__.ExistingClass"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(func.__annotations__.values())\n",
    "next(iter(func.__annotations__.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ExistingClass.func'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = ExistingClass(1)\n",
    "t.func.__qualname__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ExistingClass(1)\n",
    "test_eq(t.func1(2), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@patch\n",
    "def func3(x:(ExistingClass,ExistingClass2), a):\n",
    "    \"test\"\n",
    "    return x+2*a\n",
    "\n",
    "t = ExistingClass(1)\n",
    "test_eq(t.func3(2), 5)\n",
    "test_eq(t.func3.__qualname__, 'ExistingClass.func3')\n",
    "t = ExistingClass2(1)\n",
    "test_eq(t.func3(2), 5)\n",
    "test_eq(t.func3.__qualname__, 'ExistingClass2.func3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def patch_property(f):\n",
    "    \"Decorator: add `f` as a property to the first parameter's class (based on f's type annotations)\"\n",
    "    cls = next(iter(f.__annotations__.values()))\n",
    "    return patch_to(cls, as_prop=True)(f)\n",
    "\n",
    "@patch_property\n",
    "def prop(x:ExistingClass): return x+1\n",
    "\n",
    "t = ExistingClass(1)\n",
    "test_eq(t.prop, 2) # ExistingClass obj now have 'prop' as property (getter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to \n",
    "class ExistingClassTemp(int):\n",
    "    @property\n",
    "    def prop(self): return self+1\n",
    "    \n",
    "t = ExistingClassTemp(1)\n",
    "test_eq(t.prop, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization, type notation to work with tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0, 164, 239,  26,   0,   0,   0,\n",
       "           0,  96, 236,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  12,  47,   0,   0,   0,   0,\n",
       "           0, 179, 235,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t_float # t is now float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img = norm(t,127,50)\n",
    "n_img[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.2250)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupl = (t,1) # assume a image t with label '1'\n",
    "\n",
    "# normalization is (or should be) done on the gpu, and it will be in a 'batch' form with a bunch of tuple of (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), -2.52)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = norm(tupl,m=127,s=50) # need keywords for @Transform norm\n",
    "temp[0][12:15],temp[1] # but we don't want label to get transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x:torch.Tensor,m,s): return (x-m)/s #type notation added: determine which of the tuple to apply tfm\n",
    "\n",
    "# # equivalent to\n",
    "# def _norm(x: torch.Tensor,m,s): return (x-m)/s\n",
    "# norm = Transform(_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = norm(tupl,m=127,s=50)\n",
    "temp[0][12:15],temp[1] # fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tupl2 = (t,t,1)\n",
    "temp2 = norm(tupl2,m=127,s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]),\n",
       " tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]),\n",
       " 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2[0][12:15],temp2[1][12:15],temp2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupl2 = ((t),(1))\n",
    "temp2 = norm(tupl2,m=127,s=50)\n",
    "temp2[0][12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tupl2 = ((t,t)) # with tuple size 1, auto simplify to (t,t)\n",
    "temp2 = norm(tupl2,m=127,s=50)\n",
    "temp2[0][12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "            0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "            0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.]]),\n",
       " tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that tuple of tuple won't work. Conclusion: @Transform meaning it will goes to each value of a tuple \n",
    "# (after tuple simplification). If value of a tuple is not torch.Tensor as described => don't transform.\n",
    "tupl2 = ((t,1),t) # tuple2[0] is not torch.Tensor, tupl2[1] is\n",
    "temp2 = norm(tupl2,m=127,s=50)\n",
    "temp2[0][0][12:15],temp2[1][12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "           0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "           2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "           2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "           1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent to this long ass custom Transform class (good for pipeline I guess)\n",
    "class NormTfm(Transform):\n",
    "    def __init__(self,m,s):\n",
    "        self.m,self.s = m,s\n",
    "    def encodes(self,x:torch.Tensor): \n",
    "        return (x-self.m)/self.s\n",
    "    \n",
    "norm = NormTfm(m=127,s=50)\n",
    "temp_pipe= Pipeline([norm],as_item=False)\n",
    "temp =temp_pipe(tupl)\n",
    "\n",
    "temp[0][12:15],temp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic markers to existing type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??TensorBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTensorImg(TensorBase): pass # Note: this is just a fastai wrapper class for pytorch FloatTensor\n",
    "# Answer: fastai wants to add 'semantic markers' to original type to represent 'different kinds of information' (such as to show using show()),\n",
    "# aside from what the original type has to offer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t = MyTensorImg(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, torch.Tensor, 'torch.FloatTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t),type(t),t.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm(x:torch.Tensor,m,s): return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(t,m=127,s=50)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(my_t,m=127,s=50)[12:15] # still works\n",
    "#because MyTensorImage is a child of torch.Tensor, as type notation will allow children of the type specified in the func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def norm2(x:MyTensorImg,m,s): return (x-m)/s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "           0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "           0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.],\n",
       "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(t,m=127,s=50)[12:15] # not working, since torch.Tensor is not the same or children of MyTensorImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm2(my_t,m=127,s=50)[12:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inherit from Transform (to keep a state/attribute for your transformation + use encodes/decodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to 'encode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(Transform):\n",
    "    def __init__(self,m,s):\n",
    "        super().__init__()\n",
    "#         store_attr(self,'m,s')\n",
    "        self.m,self.s = m,s\n",
    "    def encodes(self,x:torch.Tensor): return (x-self.m)/self.s\n",
    "    def encodes(self,x: MyTensorImg): return (x-self.m)/self.s\n",
    "    # add other type for encodes here if you want\n",
    "    \n",
    "    def decodes(self,x: MyTensorImg): return (x*self.s)+ self.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent. You can add encode/decode dynamically\n",
    "# class Norm(Transform):\n",
    "#     def __init__(self,m,s):\n",
    "#         super().__init__()\n",
    "#         self.m,self.s = m,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Norm\n",
    "# def encodes(self,x:torch.Tensor): return (x-self.m)/self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Norm\n",
    "# def encodes(self,x:MyTensorImg): return (x-self.m)/self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, torch.Tensor)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t),type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Norm(m=127,s=50)\n",
    "f(my_t)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          0.7400,  2.2400, -2.0200, -2.5400, -2.5400, -2.5400, -2.5400, -0.6200,\n",
       "          2.1800, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.3000, -1.6000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,  1.0400,\n",
       "          2.1600, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.3800,  1.9200,\n",
       "          1.9000, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(t)[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t_norm = f(my_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000, 164.0000, 239.0000,  26.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,  96.0000, 236.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,  12.0000,  47.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000, 179.0000, 235.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           8.0000, 223.0000, 222.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.decodes(my_t_norm)[12:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple transform in one go = Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 1: use compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(9).view(3,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 0],\n",
       "        [5, 4, 3],\n",
       "        [8, 7, 6]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flip(x,[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def flip_img(x:MyTensorImg): return torch.flip(x,[1]) # flip among axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_norm =Norm(m=127,s=50)\n",
    "f_compose = compose(f_norm,flip_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg,\n",
       " __main__.MyTensorImg,\n",
       " 'torch.FloatTensor',\n",
       " 'torch.FloatTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = f_compose(my_t)\n",
    "type(temp),type(my_t), temp.type(),my_t.type() # type reserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that torch.flip won't reserve fastai type using type(), but at the @Transform decorator and it will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, 'torch.FloatTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.flip(my_t,[1])),torch.flip(my_t,[1]).type() #not reserve because torch.flip return tensor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, 'torch.FloatTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(flip_img(my_t)),flip_img(my_t).type() #force reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-cbfda337d5f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# but no decode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf_compose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# but no decode\n",
    "f_compose.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Transform.decode of Transform: False (MyTensorImg,object) -> flip_img >"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flip_img.decode # thanks to @Transform, flip_img can still have a dummy decode function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## option 2: use pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that Pipeline will convert everything into Transform, so no need for Transform annotation like in option 1\n",
    "\n",
    "# @Transform: this is no need\n",
    "def flip_img(x:MyTensorImg): return torch.flip(x,[1]) # flip among axis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_norm =Norm(m=127,s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "        [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "         -2.5400, -2.5400, -2.5400, -2.5400]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img])\n",
    "temp = p(my_t)\n",
    "temp[12:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(__main__.MyTensorImg, 'torch.FloatTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(temp),temp.type() # Pipeline also do type reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(p.decode(temp)) # reserve original type when decode as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 236.0000,  96.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,  26.0000, 239.0000, 164.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 235.0000, 179.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,  47.0000,  12.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000, 222.0000, 223.0000,   8.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.decode(temp)[12:15] # note that only f_norm decode is called. flip_img does not have decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With tuple as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.MyTensorImg"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(my_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_t_tuple = (my_t,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  2.1800, -0.6200, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.0200,  2.2400,  0.7400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  2.1600,  1.0400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -1.6000, -2.3000, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400],\n",
       "         [-2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400,  1.9000,  1.9200, -2.3800, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400, -2.5400,\n",
       "          -2.5400, -2.5400, -2.5400, -2.5400]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img])\n",
    "temp = p(my_t_tuple)\n",
    "temp[0][12:15],temp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 164., 239.,  26.,   0.,\n",
       "            0.,   0.,   0.,  96., 236.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,  47.,   0.,   0.,\n",
       "            0.,   0.,   0., 179., 235.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.],\n",
       "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   8., 223., 222.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "            0.,   0.,   0.,   0.]]), 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([f_norm,flip_img],as_item=True) # note again: as_item=True will force the input as a whole object. So this object is gonna be type 'Tuple'\n",
    "temp = p(my_t_tuple)\n",
    "temp[0][12:15],temp[1] #there is no encode(...,o:Tuple), so no transformation is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify output of function (not working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Transform\n",
    "def create_image_tensor(x): return tensor(array(load_image(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/quantran/.fastai/data/mnist_tiny/train/7/9286.png')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, 'torch.ByteTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_image_tensor(fn)\n",
    "type(temp),temp.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify/cast output type (NOT WORKING NOW)\n",
    "@Transform\n",
    "def create_image_tensor(x)->TensorImage: return tensor(array(load_image(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pathlib.PosixPath"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = create_image_tensor(fn)\n",
    "type(temp) #TODO: that does not work... it should return fastai torch_core.TensorImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Pipeline(create_image_tensor)(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??TupleTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metaclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my own note: https://colab.research.google.com/drive/1FN8JmmY7nr0fHJ4bTkTOYOrkGQzhKyyB#scrollTo=VS4D0EoBKJVS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type**: a class to construct other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type, __main__.Foo)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Foo(object): \n",
    "    a=1\n",
    "type(Foo),type(Foo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'a': 1,\n",
       "              '__dict__': <attribute '__dict__' of 'Foo' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Foo' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(type, __main__.Foo)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# equivalent\n",
    "Foo = type('Foo',(object,),{'a':1})\n",
    "type(Foo),type(Foo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'a': 1,\n",
       "              '__module__': '__main__',\n",
       "              '__dict__': <attribute '__dict__' of 'Foo' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Foo' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Foo.__dict__ # notice that in both cases, the class attribute 'a' is stored in __dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also note that Foo will inherit every function in type, because it's a 'type' type. Try to do Foo._ and tab for autocompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own 'type': a class to construct other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_func2(): return 'some_func2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _M(type):   \n",
    "    @classmethod\n",
    "    def __prepare__(cls,name,bases): # this is called first when you define the class with _M as its type\n",
    "        # this function will prepare the class namespace, aka __dict__ object\n",
    "        \n",
    "        print('class method __prepare__ in _M')\n",
    "        print(name,bases) #name is the name of class with _M as type\n",
    "        return {'a':1,'some_func2': some_func2} \n",
    "        # this will be added to class (instance of type) dict. Also this will be input param in __new__ below (as dict) \n",
    "    \n",
    "    # => to add class attributes to anything constructed by this _M (will be shown in __dict__)\n",
    "    \n",
    "    \n",
    "    def __new__(cls,name,bases,dict): # this is called second\n",
    "        print('__new__ in _M')\n",
    "        print(name,bases,dict)\n",
    "        return super().__new__(cls,name,bases,dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class method __prepare__ in _M\n",
      "T ()\n",
      "__new__ in _M\n",
      "T () {'a': 1, 'some_func2': <function some_func2 at 0x7f85bd116050>, '__module__': '__main__', '__qualname__': 'T', 'some_func': <function T.some_func at 0x7f85bd12d7a0>}\n"
     ]
    }
   ],
   "source": [
    "class T(metaclass= _M): # construct class T using _M as a metaclass\n",
    "    def some_func(self): return 'some_func'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'a': 1,\n",
       "              'some_func2': <function __main__.some_func2()>,\n",
       "              '__module__': '__main__',\n",
       "              'some_func': <function __main__.T.some_func(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'T' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'T' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.T.some_func(self)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.some_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some_func2\n"
     ]
    }
   ],
   "source": [
    "print(T.some_func2()) # class function can only be called by class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "some_func2() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-b1db9b3440c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msome_func2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# will return error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: some_func2() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "print(T().some_func2()) # will return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "some_func\n",
      "<__main__.T object at 0x7f85bd0fee50>\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "temp = T()\n",
    "print(temp.a)\n",
    "print(temp.some_func())\n",
    "\n",
    "print(temp)\n",
    "print(temp.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1,2}\n",
    "a.add(3)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
