{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/sgugger/.fastai/data/mnist_tiny/train/3'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7861.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7582.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/8450.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/9380.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7214.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7794.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7634.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/992.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/8710.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/9913.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o, **kwargs): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    valid = Path(fname).read().split('\\n') \n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o, **kwargs):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = o[col].values\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "        \n",
    "    def __call__(self, o, **kwargs):\n",
    "        res = self.matcher(str(o))\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{os.path.sep}(\\d){os.path.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader():\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr(self, 'suff,label_delim')\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "    \n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "    \n",
    "    def __call__(self, o, **kwargs): return detuplify(tuple(self._do_one(o, c) for c in self.cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [('0a1', '0a1'), ('0b1', '0b1'), ('0c1', '0c1'), ('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.vocab is None and dsrc is not None: self.vocab = CategoryMap(dsrc, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "        \n",
    "    def setups(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsrc: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], tensor([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): self.c = c\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.c is None: self.c = len(L(getattr(dsrc, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab): self.vocab,self.c = vocab,len(vocab)\n",
    "    def encodes(self, o): return TensorCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dbunch):\n",
    "    if getattr(dbunch, 'c', False): return dbunch.c\n",
    "    if getattr(dbunch.train_dl.after_item, 'c', False): return dbunch.train_dl.after_item.c\n",
    "    if getattr(dbunch.train_dl.after_batch, 'c', False): return dbunch.train_dl.after_batch.c\n",
    "    vocab = getattr(dbunch, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `DataSource`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7861.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/7582.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/train/3/8450.png')],\n",
       " (#3) [Path('/home/sgugger/.fastai/data/mnist_tiny/valid/3/8171.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/valid/3/7529.png'),Path('/home/sgugger/.fastai/data/mnist_tiny/valid/3/8087.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = DataSource(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEIElEQVR4nO2aPUtsVxSGn+X1WxEbFSQqEoRARAUtTKOxUSF/wCAiQlRSiYqFNjY2QWwipjCFhZYRsUlhIUFiJVH8iGgIgoJcULFQdNAYd4pxz3h2RmdwHM/ce9cDw3H2PnP24j2v66y9ZsQYgxImxe8Akg0VxEEFcVBBHFQQBxXEQQVx8F0QEZkTkfciciEif4nId77G43dhJiJfAn8bY25E5AvgN+AbY8wffsTju0OMMX8aY27s24fX537F47sgACLyk4hcA3vAe+BX32Lx+1/GIiLvgK+Ar4EfjDH/+BFHUjgEwBjzrzHmd+Az4Hu/4kgaQR6RyqeaQ0SkUETaRCRXRN6JSAvwLbDsW0x+5hARKQB+AaoJ3pxD4EdjzM++xZQsSTVZSMYc4isqiIMK4qCCOKRGmf+YM65EGlSHOKggDiqIgwrioII4qCAOKoiDCuKggjioIA4qiIMK4qCCOETb7SaU4+NjAI6OjkJjZWVlABQXF/sSkzrE4VUcsrGxAcD+/r5nfGRkBACRiK0Hzs/PAbi8vAyN5eXlAbC5uQlASUnJa4QYM+oQh2hfQzw72dTUBMDKykrE+fv7ewBSUoK6Z2dnA1BYWBi8+MPap6enXF9fez5bXV0NwPr6+nMhxIN2zGIhrhxiHZKTk+MZ7+/vjzheVFQEQHl5OQB3d3cAtLe3Mz8/7zl3aWkpntBejDrEIa4cEi/Dw8MAjI+Ph8Y6OjoAmJmZSeTSoDkkNt60Uj07OwNgbGwMgMnJSSBYp9i/e3t73zKk/6EOcXgThwQCAQAmJiaAsDNsfTI1NUVPTw8ANzc3nuNTZGRkeI6vRUKTqhWisrISgMPDQ898VlYWEE6kADs7OwCsrq4GA3yi7K+vrwegqqoKgM7OTgBqa2sBSE2Neq81qcZCQh0yOzsLQFdXV+SLP6wdyQV2zpbwW1tbMX22oaEBgOXlqD9TU4fEQkIdcnFxAUBjY2NwsYe72dbWFrz4o7tsx/Lz8z3XSE9PB+D29tYzbpNuc3MzANvb2555uy14BnVILCT0sWubPbaB9BSBQCD0BDo5OQGgrq7Oc05mZqbnvS373dxiH+kvRR3i4GuT2TI4OBhqNE9PT0c8x9Y0o6OjQLjIs3mpu7vbc3wp6hAHXx1ydXUFwMLCQqjCLCgo8JxzcHAAwNDQEACLi4tAuB1pG9kDAwMApKWlxRWTOsTBV4fYvUxLSwtzc3MAVFRUAOGNn20Z2Ca0rWmsU3Jzc181JnWIg68OsS7o6+tjb28PgLW1Nc9caWkpEGwRALS2tiY2poRe/QPE1ybzY+y+Z3d3FwhXpjU1NYlaUvcysZA0DvEBdUgsqCAOKoiDCuKggjioIA4qiIMK4qCCOETb7Ub+YvUjRh3ioII4qCAOKoiDCuKggjj8ByGsLV3mPVo8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 10 #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1, split_idx=None, as_item=True):\n",
    "        super().__init__(split_idx=split_idx,as_item=as_item)\n",
    "        self.div,self.div_mask = div,div_mask\n",
    "\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.div_(self.div_mask).long()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor(as_item=False)\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)): self.mean,self.std,self.axes = mean,std,axes\n",
    "    \n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "    \n",
    "    def setups(self, dl:DataLoader): \n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch() \n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor, Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()/255.<1\n",
    "assert 0<xd.std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAFJ0lEQVR4nO2bbWxURRSGn7PbUgrEQgpFTT8ILZUPEUO1CCFRExDUEqIRFYMhgCJFicaPaJQQY0wQQRIUJUKMP0o1BAH1RzEqWLEC8QMUQwQkFlpCMajQKqWl3Y4/pgV2uiy32+3eVc+TNN3Ozr17+s57Z86Zu1eMMSgXCPgdQLKhgjioIA4qiIMK4qCCOKggDr4LIiLrRaRORBpE5JCIPORrPH4nZiIyCjhsjGkWkeFAJXCnMeZ7P+Lx3SHGmP3GmOaOP9t/8v2Kx3dBAETkLRFpBA4AdUCFb7H4fcl0ICJBYDxwC7DMGNPiRxxJ4RAAY0zIGFMFZAOlfsWRNIJcRAr/1zlERLJE5H4R6SciQRGZAswEtvsWk59ziIgMAj4AxmAH5yjwujFmnW8xJcukmiwk4xziKyqIgwrioII4pER7c3Jgxn92xv2sbaNEaleHOKggDiqIgwrioII4qCAOKohD1Dwk3pydXgxA+kffAPDbogkAhNIv9ClfuBKAUam9AAiKHbOCcrtnVPBeAwBm7/4eiVEd4hC1/I9Xppr59QAAHr1qGwCbT90AwOKsKgD6BdI8n+ud+lwAPp4+DoDQL7/GFJNmqh7p0Tnkz7njASjPXQFARqA3AMVXftvew7szOpiXUQPAsuenAlA4p5tBOqhDHHrUIZll9m7kySX2cp1fbUf14MksAEL7rwAgf10tJ+7IAWDAQXsTr3q6XWUO3PtmxHP/NNm23z3hEQBk549xiVkd4tCjDjEt5wAoLX0cgL577fWffSI8h2gFBr59DIBg/wwARrzYJ+q50yTVvpCIi0XMqEMcEpKppm21q0qrh76np4wA4MthkeeORmNdV/zukwAU1NR6PrcX1CEOCa1lLkVTSTG/zzkDwNYbV7S3pkfsO3HVUwAMWb4TiJ8zOlCHOCTUIdJewQaGDQGgfqUd39cK11B0PmmN7IzZRyYBkLvpOBB/Z3SgDnFIqEOOvmCr3H0Pv+H5mAW1NwNQf4+1UGvdkXiHFYY6xCEhDjk121a9X81b3t7S2/OxB07buqfltsEABEJDAMhYvztu8V1MUiy70agcvdG+GG1/tZgQAEUFTwCQt9QWkKa5udOxsaCXjENCthA76LtjEAAb8j8Jaz/WepZJW54Oa2vr3QbAoWlrop5zZNljAAx9bleXYtEtRI8k1CEpeXYTyPRxJtXWUOfN4kAQgOA1QwFoWd0EQMXwD8O6PXPCbjb/XNS1VE0d4pGEOqQ7pORkA5C1sR6AtTmVAOw7Z1edhUvsJlT/Mm9ziTrEIzHlIW0TrwegZqotxHI+tzlAsHJPnMLqTM199gbVmLSqsPbretm5puqV1QCUlBV163PUIQ4xOeTwLFvGH5pmR2XXA3aUFuyZBcDAsvAN4j4VPwAQGjcSgObMXpf9jL/m2pvapYU7AJjRz24cubc9q1vt6vPy8dvbWxq8/yMRUIc4xLTKbDpmC6vztwIuw017ZgKwdMQWAG5Nb+pSkNEYu2oRAFe/urNLx+kq45GY5pCS+XZUXlptn+IYnxaK2n/32Pdj+ZioLPtjFAA5m+sAiB6Bd9QhDt3KVBvvsnVE0eLwR2wHpv4NwLOZ3f/a0xdnbd1TUT8GgG0b7NeyzjvjcHVM59U5xCM9UssEB9ttv9oHC6L2O3OtzXAPTl7b6b3h2+0T73llNsdJ/fS7WEK5JOoQj/xrqt14ow7xiArioII4qCAOKoiDCuKggjjos/8O6hAHFcRBBXFQQRxUEAcVxOEf7rNnM4+Q20cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEzElEQVR4nO2bfWhVZRzHP7/de91cG+ZbhjO16UxbZIoxDIWilsmoWGS2Ii1okURWiL0QiBFEgfWHtfwjMgMLMSOkSLMMpdHUFMGXsqW5tc1NDF9z3eG99+mP5x6vPnvxLM7uudTvA5fLdp5zz5fv+d7n/n7Pc68YY1Ay5IUtINdQQxzUEAc1xEENcVBDHNQQh9ANEZG1ItIuImdFpFFEngxVT9iFmYiUA4eNMV0iMhnYBlQZY/aEoSf0hBhjDhpjurw/048JYekJ3RAAEXlfRDqBQ0A78HVoWsJ+y3iISASYCdwOvGWMuRCGjpxICIAxJmmMqQfGAIvC0pEzhlxClP/rHCIi14jIwyJSJCIREZkD1ADfh6YpzDlEREYCG4Cp2JvTDKw0xnwQmqZcmVRzhVycQ0JFDXFQQxzUEIdoXwcr8+b9Z2fcb1OfSU//14Q4qCEOaoiDGuKghjioIQ5qiEOfdUhQHH1jJgAHF74HwOELdgn1vnVLACjZniB/00/ZkHJFNCEOWUlI4ipb8KZIAVAaiwFw4LGVAJx8pIvOdE1c9fFSO+adnwFInj6TDYkX0YQ49LlAFFQvk1dQAEDi1ikAnH7pPAD10z7JjEnfGy9F9XF7zrutdwFwou56AIrW7whCkvYyfslKQrpdND8fgKPLpgOwuPornhrSBGQS4nIsYT+ZljRXA9CyZiIAIxv+BCD5y2/90qAJ8UkoCXGJTJpAfOzVAMReOQ7AmrJ1AAyL5Pd57o3rnwVg4gv9m1s0IT7JiYT0xKnHbXW7YtkqACrye97q/aZzCAB1ZZP69fqaEJ9kpVLtDYnay5vpU/j79b8ASBl74+4Y1QD0ngyPXeeD3QbWhDhkNSHRktEA/F47HoCCaScB2DFjdbdKtTd2d0UA2HR2KgB7FpSnjxwKRKMmxCErCYmU3wDA/M+32ufijVc852TSVqZeF1z5pV07mbwyXZk2HkmPDCYZHpoQh6wkJF5SDMD84vZexzzRfCcAu7bbjrhkewKAwv1tAJS17QQgOWAqLVkxJLZlNwCVBx4CYOtNG7qNWTt+GwAVq6whgzbbJcVEFvRdir5lHLJaukemlAFwZPlgAPbN+vDiMe9j90wqDsDzLVUAnHrANneJjuNBStHS3S/hLBClS3aZbBd5Zn+6l6XD7aKyW5gtbJoDwLn5NlWJ1rZANGhCfJIT7X/0ujE0PzoWgB+eWQFAYV7ssjFzFz4NQOy7YH4koQnxSajtv0eipZWSN1sBOLHIhnJcSLdKE+IwIAlJzboFgFiH3YaMlw4HYPC+FqDnmiIy0W5ExagfCEm+0YQ4BJKQ6LWjAGiqGwHAFzPqANh47mYAFg+1LfrsVxcDMKK+EIDksCIA/phbTO28zQCMjva97TDQaEIcAklIa41d6P2x4m0ACmQQkEmGR2ntrwDc8/IBAGqKM1VnZgnR4m1dPtf0IACDD3UAA9/9akIcAq1UG1fPAGD/3farUzGJ+D7XS4j3dasFr9klw2EfNfRHgm+0UvXJgPQyx168DYCuoZefXnvvFqD73FLdeD+Hd44DYMLyvQCk4vF/c2nfaEJ8khPdbhhoQnyihjioIQ5qiIMa4qCGOKghDvrbfwdNiIMa4qCGOKghDmqIgxri8A/sIHHr3InLBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEIElEQVR4nO2bS2xUVRjHf99M2xlKy2BLCSIbtFYRYg2JpNbEuEHxGSlKIAQ3GMVUEqtiXBBMJNHoxlJEJMS4qQ8ialloTBQxxgBRkbSx4gObYIKNr0gEah/MHBd3pjCf7WSScu+56vdLZjH3nLnz5T+/Ofecc2fEOYdxjoTvAuKGBaKwQBQWiMICUVggCgtE4T0QEekWkUER+VNEvhOR+7zW43tiJiILgWPOuRERuRL4GLjNOXfYRz3eDXHO9TvnRgpP84/LfNXjPRAAEXlRRIaAb4BB4D1vtfj+yhQQkSRwHXAj8KxzbsxHHbEwBMA5l3XOfQrMAx70VUdsAjmPCv6vY4iIzBaRVSJSIyJJEbkZWA185K0mn2OIiDQAe4Bmgg/nONDlnNvlraa4DKpxIY5jiFcsEIUForBAFBWlGpcm7vnPjrgf5N6UiY6bIQoLRGGBKCwQhQWisEAUFojCAlFYIIqSM9WwSNTWAvDtM1cBMNC2k0vfeQCAxu5hAORgr4/SzBCNF0N+u3sRAANtO8aPDSzfCcDgHacBuPPJjQDUvXIw0trMEIUXQ+r6T0/adnFFDQD7tzwPwOIrOgCY/0Q0ppghipKbzGHthyTSaQBOLr8GgK1Pb2NuMri9Oy9vSIFfsmcAuP71xwBo3HwEgNzw8JRqsP2QMvFiyEQkmhcA0PHWHgBuqp741m7L4+sByHQfmtL7mSFl4uUqo0mk0/yxKAPA4tTJ/NHpRX1+PBtcmWb2nwKCH5GEUktI5/3X4sWQv+5aAsCJFcE4kZo2xtetL+Vbp0/4mrYtwcy1/ki48xEzRBGpIclZ9QDs6NwKwMKqaZP2/SQ/zXj4ueC3Mw0vfxZucXnMEEWkhvy8ogkobUaBTY/cD0BDT7Sr3UgDmX0ouKS+P5QCYFn1yKR9X+jsAmBjT0v4hZ2HfWUUkRqS6z0KQNettwPQvr4BgN6VndQk0kV9F1RWAnBqVWBI7RtTm6qXixmiiMXiruKSuRzfdhEAX7W8WtTWdmwpAGdu+PWCvqct7sokFoGcPfET2b4M2b6M71LiEUiciMXyPzmrnk2rdxcdG8qNAvDD25cDMIcLO4ZMhhmi8GpIcsYMAGbuzbGm9veiti9GqwCY03kg0prMEIUXQ5L1dQBU9wSfx2vzPxxv6xsN1v2b2zcAkOLzSGszQxSRGOJamwH4fm2wyt29bDsAS1KV433GXBaAjnXtAKT2RWtGATNEEaohI7dcC8DeXcHeRiZR2Biq/EffpneDG1BNnswoYIYoQjVksDU4/Tkzijk6OgTAQ+s20LT/yzBLKRszRBGqIY3bBwDoWxvMLa6uKt4Vu/epRwGo2xftRnIpzBBFLHbMfGA7ZmVigSgsEIUForBAFPbff4UZorBAFBaIwgJRWCAKC0TxN60V/ckSj4gZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEuElEQVR4nO2bfWhVdRjHP8+9dzO1Gu7FhU6ZtdleMDFbJGHrn7ASJJIgCWGSEBKJhCQUGf3RH2ERDOmP9YKRzLJYZS/IFFloJdjKVUObabNBonvRbeFa272//vjdO70P43rd3XYu9Xxg3N3n/M45D9/zPc95zu+cK845jCuEgk4g2zBBFCaIwgRRmCAKE0RhgigCF0REdovIOREZEJEOEdkYaD5BN2YiUg385pwbFpEKoAVY7ZxrDSKfwB3inGt3zg0nvsb/bgsqn8AFARCRN0XkMnASOAd8FVguQZ8yCUQkDKwA7gdedc6NBJFHVjgEwDkXdc4dAUqATUHlkTWCXEWE/2sNEZG5IvK4iNwoImERWQWsAw4FllOQNUREioCPgaX4g3MWqHfOvRVYTtlSVLOFbKwhgWKCKEwQhQmiiKRa+EDosf9sxT0Q+0jGi5tDFCaIwgRRmCAKE0RhgihMEIUJojBBFCaIwgRRmCAKE0SR8m53qonVLgOg7/YbxmL5J/4GIHT4x0ByMocoJsUhl9avAKC/LHmK4fUn3gUg6sbXvTr3CAAlkRljsbOj/wCwacNmn+Ch6X3mbQ5RZOSQmuNRAF4q2jnu8hwJAzDi/Ljz0SEAfhieC8DJkUIAZkgPxeGZACyK+Hry6M5mAPZVFWSS4nVjDlFk5JDG43cD0Fc9Oyn+TeOdAOT8lTwle1PXKAC5+48BEJo1y8ebZ/L+ov1JYz9ff1/8v/ZMUrxuzCGKjBxSXuevAKdV/Ba+TWv90++UA/DzorfHYg+fWOsTa51eZyQwhyimtVOV5dUA/PliDID2Gt+nxICqD58BoPy57wH/olkQmEMU0+KQyPx5AJza6neXcEaiP7njg82UbT0KQKgg369UmJ96oz19AER7+yY310ndmt54XIinWloAWDWrH/CnCEBfzLfp+ZW9XPzSF9jVJb6YPl94ID42MTqZHb1LANjX5T9jTb7JK9rT5r9fvjyhnO2UUaR8gyjTh92dr/ibvp/q6sddHoofj/FckFjW0F8KwMa8M2mt+/KF5QC0Lkt9rO1hd5pMqUPCi/3blWs+9QUzGtf/tcMPxvceH+jg1r3+SM/oupS8kYsD/nPOzUnhWJ5v+x95z7+wuCGvM2n5mvk1KXMzh6TJlF5loh2+qf+kqigpvphjyUnMn0f/PQsAGFzgpwbm7PoueWPd3Ulff9+zFIAn8/6IR/yxrdj7NABlHJ1QzuYQRaCTzAm6G2Zz11zfP5x6tnLcMYme5vQbfsKo/d5E2+9rT23bOgAWb2+PxyeGOUQRqEMipQsB2FnVyK6elQDktPm6E42PGX7IXy2Kt/8KQNPCzwA4H/W/OVrZvAWAym2+T4kODmaUkzlEMaV9yDV3npMLQHR/MV9UNAHw9ZDvL0bwE9RLcnsAKA77RxXbL3jH/LK2FIDRM50T2rf1IWkSaA1xI/5ud2BXCfXbKgDYMqcDuDI1cHDI9yUvNNQBMG9HYnqyc0pyMocoAq0hV5O477lQ6x0RGfK7zts9sY7zWlgNSZOs6FThyn1PQYd+qDG9mEMUJojCBFGYIAoTRGGCKEwQhQmiMEEU9tt/hTlEYYIoTBCFCaIwQRQmiOJfY7hBhX7OhnQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.learner.ipynb.\n",
      "Converted 43_tabular.model.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
