{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *\n",
    "from fastai2.data.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data block\n",
    "\n",
    "> High level API to quickly get your data in a `DataBunch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformBlock -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TransformBlock():\n",
    "    \"A basic wrapper that links defaults transforms for the data block API\"\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dbunch_kwargs=None):\n",
    "        self.type_tfms  =            L(type_tfms)\n",
    "        self.item_tfms  = ToTensor + L(item_tfms)\n",
    "        self.batch_tfms =            L(batch_tfms)\n",
    "        self.dl_type,self.dbunch_kwargs = dl_type,({} if dbunch_kwargs is None else dbunch_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def CategoryBlock(vocab=None, add_na=False):\n",
    "    \"`TransformBlock` for single-label categorical targets\"\n",
    "    return TransformBlock(type_tfms=Categorize(vocab=vocab, add_na=add_na))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MultiCategoryBlock(encoded=False, vocab=None, add_na=False):\n",
    "    \"`TransformBlock` for multi-label categorical targets\"\n",
    "    tfm = EncodedMultiCategorize(vocab=vocab) if encoded else [MultiCategorize(vocab=vocab, add_na=add_na), OneHotEncode]\n",
    "    return TransformBlock(type_tfms=tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from inspect import isfunction,ismethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _merge_tfms(*tfms):\n",
    "    \"Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating\"\n",
    "    g = groupby(concat(*tfms), lambda o:\n",
    "        o if isinstance(o, type) else o.__qualname__ if (isfunction(o) or ismethod(o)) else o.__class__)\n",
    "    return L(v[-1] for k,v in g.items()).map(instantiate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example, so not exported\n",
    "from fastai2.vision.core import *\n",
    "from fastai2.vision.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "tfms = _merge_tfms([Categorize, MultiCategorize, Categorize(['dog', 'cat'])], Categorize(['a', 'b']))\n",
    "#If there are several instantiated versions, the last one is kept.\n",
    "test_eq(len(tfms), 2)\n",
    "test_eq(tfms[1].__class__, MultiCategorize)\n",
    "test_eq(tfms[0].__class__, Categorize)\n",
    "test_eq(tfms[0].vocab, ['a', 'b'])\n",
    "\n",
    "tfms = _merge_tfms([PILImage.create, PILImage.show])\n",
    "#Check methods are properly separated\n",
    "test_eq(len(tfms), 2)\n",
    "tfms = _merge_tfms([show_image, set_trace])\n",
    "#Check functions are properly separated\n",
    "test_eq(len(tfms), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "@funcs_kwargs\n",
    "class DataBlock():\n",
    "    \"Generic container to quickly build `DataSource` and `DataBunch`\"\n",
    "    get_x=get_items=splitter=get_y = None\n",
    "    dl_type = TfmdDL\n",
    "    _methods = 'get_items splitter get_y get_x'.split()\n",
    "    def __init__(self, blocks=None, dl_type=None, getters=None, n_inp=None, **kwargs):\n",
    "        blocks = L(getattr(self,'blocks',(TransformBlock,TransformBlock)) if blocks is None else blocks)\n",
    "        blocks = L(b() if callable(b) else b for b in blocks)\n",
    "        self.default_type_tfms = blocks.attrgot('type_tfms', L())\n",
    "        self.default_item_tfms  = _merge_tfms(*blocks.attrgot('item_tfms',  L()))\n",
    "        self.default_batch_tfms = _merge_tfms(*blocks.attrgot('batch_tfms', L()))\n",
    "        for t in blocks: \n",
    "            if getattr(t, 'dl_type', None) is not None: self.dl_type = t.dl_type\n",
    "        if dl_type is not None: self.dl_type = dl_type\n",
    "        self.databunch = delegates(self.dl_type.__init__)(self.databunch)\n",
    "        self.dbunch_kwargs = merge(*blocks.attrgot('dbunch_kwargs', {}))\n",
    "        self.n_inp,self.getters = n_inp,L(getters)\n",
    "        if getters is not None: assert self.get_x is None and self.get_y is None\n",
    "        assert not kwargs\n",
    "\n",
    "    def datasource(self, source, type_tfms=None):\n",
    "        self.source = source\n",
    "        items = (self.get_items or noop)(source)\n",
    "        if isinstance(items,tuple):\n",
    "            items = L(items).zip()\n",
    "            labellers = [itemgetter(i) for i in range_of(self.default_type_tfms)]\n",
    "        else: labellers = [noop] * len(self.default_type_tfms)\n",
    "        splits = (self.splitter or noop)(items)\n",
    "        if self.get_x:   labellers[0] = self.get_x\n",
    "        if self.get_y:   labellers[1] = self.get_y\n",
    "        if self.getters: labellers = self.getters\n",
    "        if type_tfms is None: type_tfms = [L() for t in self.default_type_tfms]\n",
    "        type_tfms = L([self.default_type_tfms, type_tfms, labellers]).map_zip(\n",
    "            lambda tt,tfm,l: L(l) + _merge_tfms(tt, tfm))\n",
    "        return DataSource(items, tfms=type_tfms, splits=splits, dl_type=self.dl_type, n_inp=self.n_inp)\n",
    "\n",
    "    def databunch(self, source, path='.', type_tfms=None, item_tfms=None, batch_tfms=None, **kwargs):\n",
    "        dsrc = self.datasource(source, type_tfms=type_tfms)\n",
    "        item_tfms  = _merge_tfms(self.default_item_tfms,  item_tfms)\n",
    "        batch_tfms = _merge_tfms(self.default_batch_tfms, batch_tfms)\n",
    "        kwargs = {**self.dbunch_kwargs, **kwargs}\n",
    "        return dsrc.databunch(path=path, after_item=item_tfms, after_batch=batch_tfms, **kwargs)\n",
    "\n",
    "    _docs = dict(datasource=\"Create a `Datasource` from `source` with `type_tfms`\",\n",
    "                 databunch=\"Create a `DataBunch` from `source` with `item_tfms` and `batch_tfms`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a `DataBlock` you need to give the library four things: the types of your input/labels then at least two functions: `get_items` and `splitter`. You may also need to include `get_x` and `get_y` or a more generic list of `getters` that are applied to the results of `get_items`.\n",
    "\n",
    "Once those are provided, you automatically get a `DataSource` or a `DataBunch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataBlock.datasource\" class=\"doc_header\"><code>DataBlock.datasource</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBlock.datasource</code>(**`source`**, **`type_tfms`**=*`None`*)\n",
       "\n",
       "Create a `Datasource` from `source` with `type_tfms`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBlock.datasource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataBlock.databunch\" class=\"doc_header\"><code>DataBlock.databunch</code><a href=\"__main__.py#L40\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBlock.databunch</code>(**`source`**, **`path`**=*`'.'`*, **`type_tfms`**=*`None`*, **`item_tfms`**=*`None`*, **`batch_tfms`**=*`None`*, **`bs`**=*`64`*, **`shuffle`**=*`False`*, **`num_workers`**=*`None`*, **`pin_memory`**=*`False`*, **`timeout`**=*`0`*, **`batch_size`**=*`None`*, **`drop_last`**=*`False`*, **`indexed`**=*`None`*, **`n`**=*`None`*, **`device`**=*`None`*, **`wif`**=*`None`*, **`before_iter`**=*`None`*, **`after_item`**=*`None`*, **`before_batch`**=*`None`*, **`after_batch`**=*`None`*, **`after_iter`**=*`None`*, **`create_batches`**=*`None`*, **`create_item`**=*`None`*, **`create_batch`**=*`None`*, **`retain`**=*`None`*, **`get_idxs`**=*`None`*, **`sample`**=*`None`*, **`shuffle_fn`**=*`None`*, **`do_batch`**=*`None`*)\n",
       "\n",
       "Create a [`DataBunch`](/data.core#DataBunch) from `source` with `item_tfms` and `batch_tfms`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "dblock = DataBlock()\n",
    "show_doc(dblock.databunch, name=\"DataBlock.databunch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a `DataBlock` by passing functions or subclassing. The two following data blocks are the same for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(DataBlock):\n",
    "    blocks = ImageBlock(cls=PILImageBW),CategoryBlock\n",
    "    def get_items(self, source): return get_image_files(Path(source))\n",
    "    def splitter (self, items ): return GrandparentSplitter()(items)\n",
    "    def get_y    (self, item  ): return parent_label(item)\n",
    "    \n",
    "mnist = MNIST()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = DataBlock(blocks = (ImageBlock(cls=PILImageBW),CategoryBlock),\n",
    "                  get_items = get_image_files,\n",
    "                  splitter = GrandparentSplitter(),\n",
    "                  get_y = parent_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each type comes with default transforms that will be applied\n",
    "- at the base level to create items in a tuple (usually input,target) from the base elements (like filenames)\n",
    "- at the item level of the datasource\n",
    "- at the batch level\n",
    "\n",
    "They are called respectively type transforms, item transforms, batch transforms. In the case of MNIST, the type transforms are the method to create a `PILImageBW` (for the input) and the `Categorize` transform (for the target), the item transform is `ToTensor` and the batch transforms are `Cuda` and `IntToFloatTensor`. You can add any other transforms by passing them in `DataBlock.datasource` or `DataBlock.databunch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(mnist.default_type_tfms[0], [PILImageBW.create])\n",
    "test_eq(mnist.default_type_tfms[1].map(type), [Categorize])\n",
    "test_eq(mnist.default_item_tfms.map(type), [ToTensor])\n",
    "test_eq(mnist.default_batch_tfms.map(type), [IntToFloatTensor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dsrc = MNIST().datasource(untar_data(URLs.MNIST_TINY))\n",
    "test_eq(dsrc.vocab, ['3', '7'])\n",
    "x,y = dsrc.train[0]\n",
    "test_eq(x.size,(28,28))\n",
    "show_at(dsrc.train, 0, cmap='Greys', figsize=(2,2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 24_vision.gan.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.learner.ipynb.\n",
      "Converted 43_tabular.model.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted migrating.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
