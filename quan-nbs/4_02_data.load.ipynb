{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter) # 2 loaders from pytorch \n",
    "\n",
    "# these are the best things in pytorch dataloader that can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "letters = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id): # this will be called when a new process is created\n",
    "    set_num_threads(1)\n",
    "    info = get_worker_info() #pytorch function to get a worker\n",
    "    ds = info.dataset.d\n",
    "    ds.nw,ds.offs = info.num_workers,info.id # assigning things to the worker\n",
    "    set_seed(info.seed) # set fixed random seed\n",
    "    ds.wif()\n",
    "\n",
    "class _FakeLoader(GetAttr):\n",
    "    # pytorch expected object (which it works with) having these things in it\n",
    "    _IterableDataset_len_called,_auto_collation,collate_fn,drop_last,dataset_kind,_dataset_kind,_index_sampler = (\n",
    "        None,False,noops,False,_DatasetKind.Iterable,_DatasetKind.Iterable,Inf.count)\n",
    "    def __init__(self, d, pin_memory, num_workers, timeout):\n",
    "        self.dataset,self.default,self.worker_init_fn = self,d,_wif\n",
    "        #worker_init_fn is PYTORCH data loader's callback which is called everytime a new process is fired off\n",
    "        store_attr(self, 'd,pin_memory,num_workers,timeout')\n",
    "\n",
    "    def __iter__(self): return iter(self.d.create_batches(self.d.sample()))\n",
    "\n",
    "    @property\n",
    "    def multiprocessing_context(self): return (None,multiprocessing)[self.num_workers>0]\n",
    "\n",
    "    @contextmanager\n",
    "    def no_multiproc(self):\n",
    "        old_nw = self.num_workers\n",
    "        try:\n",
    "            self.num_workers = 0\n",
    "            yield self.d\n",
    "        finally: self.num_workers = old_nw\n",
    "\n",
    "_collate_types = (ndarray, Tensor, typing.Mapping, str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fa_collate(t): # fastai collate, an extension to pytorch default_collate (to turn data into a batch with batch size)\n",
    "    # similar to pytorch default_collate, but can handle few more types\n",
    "    # use only when there is a batch size (bs!=none)\n",
    "    b = t[0]\n",
    "    return (default_collate(t) if isinstance(b, _collate_types)\n",
    "            else type(t[0])([fa_collate(s) for s in zip(*t)]) if isinstance(b, Sequence)\n",
    "            else default_collate(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g. x is int, y is tuple\n",
    "t = [(1,(2,3)),(1,(2,3))]\n",
    "test_eq(fa_collate(t), default_collate(t))\n",
    "test_eq(L(fa_collate(t)).map(type), [Tensor,tuple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1]), (tensor([2, 2]), tensor([3, 3])))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_collate(t) # think of it as you inverse a matrix, but the type and structure inside are still the same\n",
    "# convert type to Tensor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.LongTensor', 'torch.LongTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_collate(t)[0].type(),fa_collate(t)[1][0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [(1,(2,(3,4))),(1,(2,(3,4)))]\n",
    "test_eq(fa_collate(t), default_collate(t))\n",
    "test_eq(L(fa_collate(t)).map(type), [Tensor,tuple])\n",
    "test_eq(L(fa_collate(t)[1]).map(type), [Tensor,tuple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1]), (tensor([2, 2]), (tensor([3, 3]), tensor([4, 4]))))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_collate(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fa_convert(t): #fastai version of default_convert. Call only when bs=None (no batch size)\n",
    "    return (default_convert(t) if isinstance(t, _collate_types)\n",
    "            else type(t)([fa_convert(s) for s in t]) if isinstance(t, Sequence)\n",
    "            else default_convert(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2]), (array([1, 2]), array([1, 2]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = array([1,2])\n",
    "t = [t0,(t0,t0)]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2]), (tensor([1, 2]), tensor([1, 2]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_convert(t) # convert array to tensor. Not doing 'matrix inverse' thing like fa_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([1]), tensor([2, 3])), (tensor([1]), tensor([2, 3]))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_convert([(array([1]),array([2,3])),(array([1]),array([2,3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, (2, 3)), (1, (2, 3))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_convert([(1,(2,3)),(1,(2,3))]) #if type is not array, keep it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.LongTensor', 'torch.LongTensor')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_convert(t)[0].type(),fa_convert(t)[1][0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(fa_convert(t), default_convert(t))\n",
    "test_eq(L(fa_convert(t)).map(type), [Tensor,tuple])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkipItemException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@funcs_kwargs # look for stuff inside _methods, and determine whether some of **kwargs in __init__ will be in this _methods, \n",
    "# then override DataLoader function with it. \n",
    "# See 'create_item' and use cases below\n",
    "# Note: what is GetAttr for? Look at note 7 tabular core\n",
    "class DataLoader(GetAttr):\n",
    "    # list of callbacks for DataLoader\n",
    "    _noop_methods = 'wif before_iter after_item before_batch after_batch after_iter'.split()\n",
    "    # after_item vs after_iter\n",
    "    # - after_item: this fn is done right after we grab 1 thing from the dataset\n",
    "    # - after_iter: this fn is done only after we iterate the whole dataset\n",
    "    for o in _noop_methods:\n",
    "        exec(f\"def {o}(self, x=None, *args, **kwargs): return x\")\n",
    "    _methods = _noop_methods + 'create_batches create_item create_batch retain \\\n",
    "        get_idxs sample shuffle_fn do_batch create_batch'.split()\n",
    "    _default = 'dataset'\n",
    "\n",
    "    def __init__(self, dataset=None, bs=None, num_workers=0, pin_memory=False, timeout=0, batch_size=None,\n",
    "                 shuffle=False, drop_last=False, indexed=None, n=None, device=None, **kwargs):\n",
    "        if batch_size is not None: bs = batch_size # PyTorch compatibility\n",
    "        assert not (bs is None and drop_last)\n",
    "        if indexed is None: indexed = dataset is not None and hasattr(dataset,'__getitem__')\n",
    "        if n is None:\n",
    "            try: n = len(dataset)\n",
    "            except TypeError: pass\n",
    "            \n",
    "        store_attr(self, 'dataset,bs,shuffle,drop_last,indexed,n,pin_memory,timeout,device')\n",
    "        # Note: replace storing class attributes like self.dataset,self.bs = dataset,bs ...\n",
    "            \n",
    "        self.rng,self.nw,self.offs = random.Random(),1,0\n",
    "        self.fake_l = _FakeLoader(self, pin_memory, num_workers, timeout)\n",
    "        \n",
    "        \n",
    "        #assert not kwargs and not (bs is None adn drop_last) \n",
    "        #remove assert not kwargs to throw error when unrecognizable things is passed in kwargs\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.n is None: raise TypeError\n",
    "        if self.bs is None: return self.n\n",
    "        return self.n//self.bs + (0 if self.drop_last or self.n%self.bs==0 else 1)\n",
    "    \n",
    "    def get_idxs(self):\n",
    "        idxs = Inf.count if self.indexed else Inf.nones # TODO: infinite list of integers if indexed=True, else infinite of None???\n",
    "        if self.n is not None: idxs = list(itertools.islice(idxs, self.n)) #TODO: checkout functional programming in Python (itertools library package)\n",
    "        if self.shuffle: idxs = self.shuffle_fn(idxs)\n",
    "        return idxs\n",
    "    \n",
    "    def sample(self):\n",
    "        idxs = self.get_idxs()\n",
    "        return (b for i,b in enumerate(idxs) if i//(self.bs or 1)%self.nw==self.offs)\n",
    "        \n",
    "    def __iter__(self): # important function: how fastai dataloaders get data\n",
    "        # callbacks used: before_iter, <create_item, after_item> (in def do_item), <before_batch,create_batch> (in def do_batch), after_batch\n",
    "        self.randomize()\n",
    "        self.before_iter() # before_iter callback\n",
    "        for b in _loaders[self.fake_l.num_workers==0](self.fake_l): # FakeLoader instance, which do create_batches\n",
    "            if self.device is not None: b = to_device(b, self.device)\n",
    "            yield self.after_batch(b) # then do after_batch afterwards\n",
    "        self.after_iter() #after_iter callback\n",
    "        if hasattr(self, 'it'): delattr(self, 'it')\n",
    "\n",
    "    def create_batches(self, samps):\n",
    "        self.it = iter(self.dataset) if self.dataset is not None else None\n",
    "        res = filter(lambda o:o is not None, map(self.do_item, samps)) # see do_item\n",
    "        yield from map(self.do_batch, self.chunkify(res)) # see do_batch\n",
    "        # btw doing lazily with map (generator). This is good: easy to understand, less bug, less code to write\n",
    "\n",
    "    def new(self, dataset=None, cls=None, **kwargs):\n",
    "        if dataset is None: dataset = self.dataset\n",
    "        if cls is None: cls = type(self)\n",
    "        cur_kwargs = dict(dataset=dataset, num_workers=self.fake_l.num_workers, pin_memory=self.pin_memory, timeout=self.timeout,\n",
    "                          bs=self.bs, shuffle=self.shuffle, drop_last=self.drop_last, indexed=self.indexed, device=self.device)\n",
    "        for n in self._methods: cur_kwargs[n] = getattr(self, n)\n",
    "        return cls(**merge(cur_kwargs, kwargs))\n",
    "    \n",
    "    @property\n",
    "    def prebatched(self): return self.bs is None\n",
    "    def do_item(self, s):\n",
    "        try: return self.after_item(self.create_item(s)) # create item and then apply after_item function immediately\n",
    "        except SkipItemException: return None\n",
    "    def chunkify(self, b): return b if self.prebatched else chunked(b, self.bs, self.drop_last)\n",
    "    def shuffle_fn(self, idxs): return self.rng.sample(idxs, len(idxs))\n",
    "    def randomize(self): self.rng = random.Random(self.rng.randint(0,2**32-1))\n",
    "    def retain(self, res, b):  return retain_types(res, b[0] if is_listy(b) else b)\n",
    "    def create_item(self, s):  return next(self.it) if s is None else self.dataset[s] # can treat both indexed and non-indexed\n",
    "    def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b)\n",
    "    def do_batch(self, b): return self.retain(self.create_batch(self.before_batch(b)), b) # before_batch => create_batch and retain same type\n",
    "    def to(self, device): self.device = device\n",
    "    def one_batch(self):\n",
    "        if self.n is not None and len(self)==0: raise ValueError(f'This DataLoader does not contain any batches')\n",
    "        with self.fake_l.no_multiproc(): res = first(self)\n",
    "        if hasattr(self, 'it'): delattr(self, 'it')\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DataLoader at 0x7f3e94994b90>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(create_batc=1) # well, not proper behavior on typo, unlike DataBunch on 3_03 notebook..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `item` and use the default infinite sampler to get a stream of unknown length (`stop()` when you want to stop the stream)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader child class that overrides create_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#19) [0.2448879411063063,0.023115802608246194,0.2516397681417346,0.8689824597369601,0.6202842409612128,0.282738303489663,0.6903038780761714,0.5454319031985198,0.39029153731457067,0.38409829020021446...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDL(DataLoader):\n",
    "    def create_item(self, s): # s can be some index. The default create_item func will do dataset[s] (or if non-index, do next(it))\n",
    "        # but we can override it with this\n",
    "        r = random.random()\n",
    "        return r if r<0.95 else stop() # keep returning number until stop condition (number >=0.95) is met\n",
    "        # stop() just raises an exception. It is how iteration in a generator knows when to stop \n",
    "\n",
    "L(RandDL())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#0) []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(RandDL(bs=4, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#16) [tensor([0.9397, 0.4274, 0.4689, 0.0060], dtype=torch.float64),tensor([0.7231, 0.0176, 0.4928, 0.4889], dtype=torch.float64),tensor([0.7878, 0.8066, 0.1979, 0.8556], dtype=torch.float64),tensor([0.0549, 0.3201, 0.1436, 0.3277], dtype=torch.float64),tensor([0.5176, 0.6728, 0.0704, 0.2168], dtype=torch.float64),tensor([0.3115, 0.3950, 0.3338, 0.4602], dtype=torch.float64),tensor([0.6882, 0.3257, 0.8847, 0.6711], dtype=torch.float64),tensor([0.2572, 0.3027, 0.8523, 0.8535], dtype=torch.float64),tensor([0.9048, 0.0431, 0.4288, 0.0712], dtype=torch.float64),tensor([0.2874, 0.9125, 0.2183, 0.9168], dtype=torch.float64)...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(RandDL(bs=4, drop_last=False)) # don't drop last batch if stop condition is met => result in batch of 3 at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) [4,4,4,4,4,4,4,4,4,4...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = RandDL(bs=4, num_workers=4, drop_last=True) \n",
    "# 4 workers working on the dataloader at the same time, independently\n",
    "L(dl).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(dl.fake_l.num_workers, 4)\n",
    "with dl.fake_l.no_multiproc(): \n",
    "    test_eq(dl.fake_l.num_workers, 0)\n",
    "    L(dl).map(len)\n",
    "test_eq(dl.fake_l.num_workers, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader that overrides create_item (no children/inheritance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#31) [0.8686841543357502,0.07343815517933427,0.5577334928343769,0.644018531735975,0.7052030486955067,0.9082687023578571,0.3882997696254147,0.5240111197056229,0.09998823746576968,0.21261268128410926...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _rand_item(s):\n",
    "    r = random.random()\n",
    "    return r if r<0.95 else stop()\n",
    "\n",
    "L(DataLoader(create_item=_rand_item)) \n",
    "# create_item callback without creating DataLoader inheritance. \n",
    "# DataLoader create_item will be overidden by this _rand_item func\n",
    "# Thanks to @func_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few other examples with dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't set `bs`, then `dataset` is assumed to provide an iterator or a `__getitem__` that returns a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = DataLoader(letters) #bs = None (or 0): get the whole thing back\n",
    "test_eq(L(ds1), letters) # NOTE that ds1 is technically an iterator, so convert it into L (array) type to check for values\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "test_shuffled(L(DataLoader(letters, shuffle=True)), letters) # you can even test if the data is shuffled properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(L(ds1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ds1)) # ds1 is still an iterator regardless of whether data is indexed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = DataLoader(letters, indexed=False) #non-indexed dataset (with no __getitem__)\n",
    "# i.e when dataset is too damn big, or you are streaming over a network, and you still want bs=0\n",
    "# Note: this case the result isn't shuffled because 'letters' itself is a list and have __getitem__\n",
    "test_eq(L(ds1), letters)\n",
    "test_eq(len(ds1), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(L(ds1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = DataLoader(letters, bs=2,indexed=False) #non-indexed dataset (with no __getitem__) and bs!=0\n",
    "next(iter(ds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#2) [tensor([0, 1, 2]),tensor([3, 4, 5])]\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "t2 = L(tensor([0,1,2]),tensor([3,4,5]))\n",
    "ds2 = DataLoader(t2)\n",
    "test_eq_type(L(ds2), t2)\n",
    "print(L(ds2))\n",
    "print(L(ds2)[0].type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#2) [tensor([0, 1, 2]),tensor([3, 4, 5])]\n",
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "ds3 = DataLoader(t3)\n",
    "test_eq_type(L(ds3), t3.map(tensor))\n",
    "print(L(ds3))\n",
    "print(L(ds3)[0].type()) # convert array to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds4 = DataLoader(t3, create_batch=noop, # create_batch == do nothing \n",
    "                 after_iter=lambda: setattr(t3, 'f', 1)) # add new attribute to input t3, after iterating it\n",
    "# after_iter callback is similar to after_item used below\n",
    "\n",
    "# tfms = [[PILImage.create], [labeller, Categorize()]]\n",
    "# dsrc = DataSource(items, tfms)\n",
    "# tdl = TfmdDL(dsrc, bs=1, after_item=[ImageResizer(128), ToTensor(), IntToFloatTensor()])\n",
    "# differences b/t after_item and after_iter? See class DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'L' object has no attribute 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-68c40bb7bccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'L' object has no attribute 'f'"
     ]
    }
   ],
   "source": [
    "print(next(iter(ds4)))\n",
    "print(t3.f) # t3.f not exist yet because we are not done iterating the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(L(ds4), t3)\n",
    "test_eq(t3.f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same examples of using callback, for some reasons\n",
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "\n",
    "\n",
    "ds1 = DataLoader([str(i) for i in range(11)], bs=4, \n",
    "                 after_iter=lambda: setattr(t3, 'f', 2)) \n",
    "# add HOOK CALLBACK func in dataloader: after_iter: add new attribute to INPUT t3 AFTER ALL THE ITERATION\n",
    "test_eq_type(L(ds1), L(['0','1','2','3'],['4','5','6','7'],['8','9','10']))\n",
    "test_eq(t3.f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = DataLoader(range(12), bs=4, num_workers=3)\n",
    "test_eq_type(L(ds1), L(tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do set `bs`, then `dataset` is assumed to provide an iterator or a `__getitem__` that returns a single item of a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d) \n",
    "# for each batch, concat chars together, then concat them together with ' ' as delimiters. Do this twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab', 'cde']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[''.join(o) for _ in range(1) for o in [['a','b'],['c','d','e']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ab cde ab cde'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twoepochs([['a','b'],['c','d','e']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = DataLoader(letters, bs=4, drop_last=True, num_workers=0)\n",
    "test_eq(twoepochs(ds1), 'abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx')\n",
    "\n",
    "ds1 = DataLoader(letters,4,num_workers=2)\n",
    "test_eq(twoepochs(ds1), 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd abcd\n",
      "\n",
      "abc abc\n",
      "abcd efgh abcd efgh\n"
     ]
    }
   ],
   "source": [
    "ds1 = DataLoader(letters, bs=4, drop_last=True, num_workers=0, n=4) # n is length of dataset\n",
    "print(twoepochs(ds1))\n",
    "\n",
    "ds1 = DataLoader(letters, bs=4, drop_last=True, num_workers=0, n=3) # when n < bs and drop_last = True, none return \n",
    "#because drop_last=true make sure last batch's size = bs. We only have 3 letters to work with.\n",
    "print(twoepochs(ds1))\n",
    "\n",
    "ds1 = DataLoader(letters, bs=4, drop_last=False, num_workers=0, n=3)\n",
    "print(twoepochs(ds1))\n",
    "\n",
    "ds1 = DataLoader(letters, bs=4, drop_last=True, num_workers=0, n=8)\n",
    "print(twoepochs(ds1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate dataloader with a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#20) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(map(noop,range(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(DataLoader(map(noop,range(20)), bs=4, num_workers=1)) # pass a generator (by using map) to DataLoader\n",
    "test_eq_type([next(it) for _ in range(3)], [tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset has \\__getitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.47 ms, sys: 536 Âµs, total: 4.01 ms\n",
      "Wall time: 292 ms\n",
      "CPU times: user 15.3 ms, sys: 13.6 ms, total: 28.9 ms\n",
      "Wall time: 173 ms\n",
      "CPU times: user 6.89 ms, sys: 32.8 ms, total: 39.6 ms\n",
      "Wall time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "class SleepyDL(list):\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(random.random()/50)\n",
    "        return super().__getitem__(i)\n",
    "\n",
    "t = SleepyDL(letters)\n",
    "\n",
    "# to test DataLoader's multiple workers (working simultaneously) still return data in a correct others\n",
    "%time test_eq(DataLoader(t, num_workers=0), letters)\n",
    "%time test_eq(DataLoader(t, num_workers=2), letters)\n",
    "%time test_eq(DataLoader(t, num_workers=4), letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) ['a','b','c','d','e','f','g','h','i','j'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(DataLoader(t, num_workers=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(t, shuffle=True, num_workers=2) # work well with multiple workers even when data is shuffled. Wow!\n",
    "test_shuffled(L(dl), letters)\n",
    "test_shuffled(L(dl), L(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) ['p','a','c','j','u','g','i','x','t','l'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset does not have \\__getitem__, only \\__iter__,  (non-indexed dataset),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can force this behavior by setting indexed=False (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyQueue():\n",
    "    \"Simulate a queue with varying latency\"\n",
    "    def __init__(self, q): self.q=q\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            time.sleep(random.random()/100)\n",
    "            try: yield self.q.get_nowait()\n",
    "            except queues.Empty: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#30) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in range(30): q.put(o)\n",
    "it = SleepyQueue(q)\n",
    "L(it) # ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#30) [0,1,2,3,4,5,6,7,8,9...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in range(30): q.put(o)\n",
    "it = SleepyQueue(q)\n",
    "L(DataLoader(it, num_workers=1)) # still ordered, with num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#30) [0,2,1,4,3,6,5,8,7,10...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in range(30): q.put(o)\n",
    "it = SleepyQueue(q)\n",
    "L(DataLoader(it, num_workers=2)) #non-indexed ds with no __getitem__ and >1 num_workers will not get your items in order \n",
    "# (aka if items have order, they will ALWAYS be shuffled). It doesn't matter whether shuffle= True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(it)) # note that with dataset with only iterator (no __get_item__), you can't continue fetching data from dataloader\n",
    "# once the iterator reaches the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.51 ms, sys: 23.1 ms, total: 30.6 ms\n",
      "Wall time: 97.7 ms\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in range(30): q.put(o)\n",
    "it = SleepyQueue(q)\n",
    "\n",
    "%time test_shuffled(L(DataLoader(it, num_workers=4)), range(30)) # test whether data is shuffled correctly, multiple workers \n",
    "\n",
    "# Note on why >1 workers for non-indexed data can't maintain order:\n",
    "# data is shuffled, since we don't know which worker will start first/finish first\n",
    "# On the other hand, for indexed workers, we can assign indices for each worker to maintain order when shuffle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) ['e','a','b','d','f','c','g','i','h','j'...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in letters: q.put(o) # another non-indexed shuffle\n",
    "it = SleepyQueue(q)\n",
    "L(DataLoader(it, num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'c', 'g', 'j']\n",
      "['b', 'd']\n",
      "['e', 'h', 'k', 'n']\n",
      "['f', 'i', 'l', 'o']\n",
      "['m', 'p', 's', 't']\n",
      "['q', 'w']\n",
      "['r', 'u', 'v', 'y']\n",
      "['x']\n",
      "['z']\n"
     ]
    }
   ],
   "source": [
    "q = Queue()\n",
    "for o in letters: q.put(o)\n",
    "it = SleepyQueue(q)\n",
    "temp_dl = DataLoader(it, num_workers=4,bs=4) # with bs!=0\n",
    "for temp in temp_dl:\n",
    "    print(temp) # different workers keeping different left-over (when drop_last = False) running in different orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTF is this: An interesting take on multiple workers changing variables asyncronously?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempClass():\n",
    "    def __init__(self, letters): self.letters,self.i=letters,0\n",
    "    def __iter__(self):\n",
    "#         time.sleep(random.random()/100)\n",
    "        while self.i< len(self.letters):\n",
    "            print(self.i)\n",
    "            yield self.letters[self.i]\n",
    "\n",
    "            self.i+=1\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#5) [a,b,c,d,e]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(DataLoader(TempClass(letters[:5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#10) [a,a,b,b,c,c,d,d,e,e]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(DataLoader(TempClass(letters[:5]),num_workers=2)) #lol what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#10) [a,a,b,b,c,c,d,d,e,e]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(DataLoader(TempClass(letters[:5]),num_workers=2)) #lol what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: what is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(TensorBase): pass\n",
    "\n",
    "for nw in (0,2):\n",
    "    t = A(tensor([1,2]))\n",
    "    dl = DataLoader([t,t,t,t,t,t,t,t], bs=4, num_workers=nw)\n",
    "    b = next(iter(dl))\n",
    "    test_eq(type(b), A)\n",
    "\n",
    "    t = (A(tensor([1,2])),)\n",
    "    dl = DataLoader([t,t,t,t,t,t,t,t], bs=4, num_workers=nw)\n",
    "    b = next(iter(dl))\n",
    "    test_eq(type(b[0]), A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(TensorBase): pass\n",
    "t = A(tensor(1,2))\n",
    "\n",
    "tdl = DataLoader([t,t,t,t,t,t,t,t], bs=4, num_workers=2, after_batch=to_device)\n",
    "b = next(iter(tdl))\n",
    "test_eq(type(b), A)\n",
    "\n",
    "# Unknown attributes are delegated to `dataset`\n",
    "test_eq(tdl.pop(), tensor(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
